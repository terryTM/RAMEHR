{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import gzip\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from node2vec import Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Patients: 46520 records\n",
      "Admissions: 58976 records\n",
      "Diagnoses: 651047 records\n",
      "Procedures: 240095 records\n",
      "Prescriptions: 4156450 records\n",
      "Lab Events: 27854055 records\n",
      "\n",
      "Creating visit-level records...\n",
      "Processing diagnoses...\n",
      "Processing procedures...\n",
      "Processing prescriptions...\n",
      "Processing lab events...\n",
      "\n",
      "Building graph...\n",
      "Adding nodes...\n",
      "Adding edges...\n",
      "\n",
      "Graph Statistics:\n",
      "Number of nodes (medical codes): 13923\n",
      "Number of edges (connections): 9129990\n",
      "Number of visits processed: 5667981\n",
      "Average node degree: 1311.50\n",
      "\n",
      "Code type distribution:\n",
      "PROC: 2009 codes\n",
      "DIAG: 6984 codes\n",
      "MED: 4204 codes\n",
      "LAB: 726 codes\n"
     ]
    }
   ],
   "source": [
    "# Set base directory\n",
    "base_dir = '/Users/terryma/Documents/physionet.org/files/mimiciii/1.4'\n",
    "\n",
    "# Load relevant tables with correct paths\n",
    "patients = pd.read_csv(gzip.open(os.path.join(base_dir, 'PATIENTS.csv.gz'), 'rt'), \n",
    "                      usecols=['SUBJECT_ID'])\n",
    "admissions = pd.read_csv(gzip.open(os.path.join(base_dir, 'ADMISSIONS.csv.gz'), 'rt'), \n",
    "                        usecols=['SUBJECT_ID', 'HADM_ID'])\n",
    "diagnoses = pd.read_csv(gzip.open(os.path.join(base_dir, 'DIAGNOSES_ICD.csv.gz'), 'rt'), \n",
    "                       usecols=['HADM_ID', 'ICD9_CODE'])\n",
    "procedures = pd.read_csv(gzip.open(os.path.join(base_dir, 'PROCEDURES_ICD.csv.gz'), 'rt'), \n",
    "                        usecols=['HADM_ID', 'ICD9_CODE'])\n",
    "prescriptions = pd.read_csv(gzip.open(os.path.join(base_dir, 'PRESCRIPTIONS.csv.gz'), 'rt'), \n",
    "                          usecols=['HADM_ID', 'NDC'])\n",
    "labevents = pd.read_csv(gzip.open(os.path.join(base_dir, 'LABEVENTS.csv.gz'), 'rt'), \n",
    "                       usecols=['HADM_ID', 'ITEMID'])\n",
    "\n",
    "# Add some basic data validation and progress printing\n",
    "print(\"Loading data...\")\n",
    "print(f\"Patients: {len(patients)} records\")\n",
    "print(f\"Admissions: {len(admissions)} records\")\n",
    "print(f\"Diagnoses: {len(diagnoses)} records\")\n",
    "print(f\"Procedures: {len(procedures)} records\")\n",
    "print(f\"Prescriptions: {len(prescriptions)} records\")\n",
    "print(f\"Lab Events: {len(labevents)} records\")\n",
    "\n",
    "# Create visit-level records with progress updates\n",
    "print(\"\\nCreating visit-level records...\")\n",
    "visit_codes = defaultdict(set)\n",
    "\n",
    "print(\"Processing diagnoses...\")\n",
    "for _, row in diagnoses.iterrows():\n",
    "    if pd.notna(row['ICD9_CODE']):  # Skip null values\n",
    "        visit_codes[row['HADM_ID']].add(f'DIAG_{row[\"ICD9_CODE\"]}')\n",
    "\n",
    "print(\"Processing procedures...\")\n",
    "for _, row in procedures.iterrows():\n",
    "    if pd.notna(row['ICD9_CODE']):\n",
    "        visit_codes[row['HADM_ID']].add(f'PROC_{row[\"ICD9_CODE\"]}')\n",
    "\n",
    "print(\"Processing prescriptions...\")\n",
    "for _, row in prescriptions.iterrows():\n",
    "    if pd.notna(row['NDC']):\n",
    "        visit_codes[row['HADM_ID']].add(f'MED_{row[\"NDC\"]}')\n",
    "\n",
    "print(\"Processing lab events...\")\n",
    "for _, row in labevents.iterrows():\n",
    "    if pd.notna(row['ITEMID']):\n",
    "        visit_codes[row['HADM_ID']].add(f'LAB_{row[\"ITEMID\"]}')\n",
    "\n",
    "# Build the graph with progress updates\n",
    "print(\"\\nBuilding graph...\")\n",
    "H = nx.Graph()\n",
    "\n",
    "print(\"Adding nodes...\")\n",
    "all_codes = set(code for codes in visit_codes.values() for code in codes)\n",
    "H.add_nodes_from(all_codes)\n",
    "\n",
    "print(\"Adding edges...\")\n",
    "for visit_id, codes in visit_codes.items():\n",
    "    codes_list = list(codes)\n",
    "    for i in range(len(codes_list)):\n",
    "        for j in range(i+1, len(codes_list)):\n",
    "            H.add_edge(codes_list[i], codes_list[j])\n",
    "\n",
    "# Print detailed statistics\n",
    "print(\"\\nGraph Statistics:\")\n",
    "print(f\"Number of nodes (medical codes): {H.number_of_nodes()}\")\n",
    "print(f\"Number of edges (connections): {H.number_of_edges()}\")\n",
    "print(f\"Number of visits processed: {len(visit_codes)}\")\n",
    "\n",
    "# Additional analysis\n",
    "avg_degree = sum(dict(H.degree()).values()) / H.number_of_nodes()\n",
    "print(f\"Average node degree: {avg_degree:.2f}\")\n",
    "\n",
    "# Print code type distribution\n",
    "code_types = defaultdict(int)\n",
    "for node in H.nodes():\n",
    "    prefix = node.split('_')[0]\n",
    "    code_types[prefix] += 1\n",
    "\n",
    "print(\"\\nCode type distribution:\")\n",
    "for prefix, count in code_types.items():\n",
    "    print(f\"{prefix}: {count} codes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating edge labels...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m edge_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m u, v \u001b[38;5;129;01min\u001b[39;00m H\u001b[38;5;241m.\u001b[39medges():\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Calculate some measure for the edge label (example: common neighbors)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     common_neighbors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(H\u001b[38;5;241m.\u001b[39mneighbors(u))\u001b[38;5;241m.\u001b[39mintersection(\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     12\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m common_neighbors \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([H\u001b[38;5;241m.\u001b[39mdegree(u), H\u001b[38;5;241m.\u001b[39mdegree(v)])\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     13\u001b[0m     edge_labels\u001b[38;5;241m.\u001b[39mappend(label)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.nn import Node2Vec\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = '/Users/terryma/Documents'\n",
    "\n",
    "# 1. Generate edge labels (can be parallelized with CUDA)\n",
    "print(\"Generating edge labels...\")\n",
    "edge_labels = []\n",
    "edges = list(H.edges())\n",
    "# Convert to torch tensors for GPU processing\n",
    "edge_tensor = torch.tensor([[u, v] for u, v in edges]).to(device)\n",
    "\n",
    "def compute_edge_labels(edge_tensor, H):\n",
    "    labels = []\n",
    "    for u, v in edge_tensor.cpu().numpy():\n",
    "        common_neighbors = len(set(H.neighbors(u)).intersection(set(H.neighbors(v))))\n",
    "        label = 1 if common_neighbors > np.mean([H.degree(u), H.degree(v)])/2 else 0\n",
    "        labels.append(label)\n",
    "    return torch.tensor(labels, device=device)\n",
    "\n",
    "edge_labels = compute_edge_labels(edge_tensor, H)\n",
    "\n",
    "# Save edge labels\n",
    "edge_labels_path = os.path.join(output_dir, 'edge-labels-mimic3.txt')\n",
    "np.savetxt(edge_labels_path, edge_labels.cpu().numpy(), fmt='%d', delimiter=',')\n",
    "\n",
    "# 2. Generate hyperedges\n",
    "print(\"Generating hyperedges...\")\n",
    "node_to_index = {node: idx for idx, node in enumerate(H.nodes())}\n",
    "hyperedges = []\n",
    "for visit_id, codes in visit_codes.items():\n",
    "    code_indices = [node_to_index[code] for code in codes]\n",
    "    hyperedges.append(code_indices)\n",
    "\n",
    "# Save hyperedges\n",
    "hyperedges_path = os.path.join(output_dir, 'hyperedges-mimic3.txt')\n",
    "with open(hyperedges_path, 'w') as f:\n",
    "    for edge in hyperedges:\n",
    "        f.write(','.join(map(str, edge)) + '\\n')\n",
    "\n",
    "# 3. Generate node embeddings using GPU-accelerated node2vec\n",
    "print(\"Generating node embeddings...\")\n",
    "# Convert networkx graph to PyTorch Geometric data\n",
    "data = from_networkx(H)\n",
    "data = data.to(device)\n",
    "\n",
    "# Initialize GPU-accelerated Node2Vec\n",
    "model = Node2Vec(\n",
    "    data.edge_index,\n",
    "    embedding_dim=64,\n",
    "    walk_length=30,\n",
    "    context_size=10,\n",
    "    walks_per_node=200,\n",
    "    num_negative_samples=1,\n",
    "    p=1,\n",
    "    q=1,\n",
    "    sparse=True\n",
    ").to(device)\n",
    "\n",
    "# Train using GPU\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for _ in range(100):  # num epochs\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / 100\n",
    "\n",
    "print(\"Training node embeddings...\")\n",
    "for epoch in range(30):\n",
    "    loss = train()\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f'Epoch: {epoch+1:02d}, Loss: {loss:.4f}')\n",
    "\n",
    "# Get embeddings\n",
    "@torch.no_grad()\n",
    "def get_embeddings():\n",
    "    model.eval()\n",
    "    z = model()\n",
    "    return z.cpu().numpy()\n",
    "\n",
    "embeddings = get_embeddings()\n",
    "\n",
    "# Save node embeddings\n",
    "embeddings_path = os.path.join(output_dir, 'node-embeddings-mimic3')\n",
    "np.savetxt(embeddings_path, embeddings)\n",
    "\n",
    "print(f\"\\nFiles saved to:\")\n",
    "print(f\"Edge labels: {edge_labels_path}\")\n",
    "print(f\"Hyperedges: {hyperedges_path}\")\n",
    "print(f\"Node embeddings: {embeddings_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
